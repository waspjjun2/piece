{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import request\n",
    "from requests.compat import urljoin, urlparse\n",
    "from requests.exceptions import HTTPError\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canfetch(url, agent='*', path='/'):\n",
    "    robot = RobotFileParser(urljoin(url, '/robots.txt'))\n",
    "    robot.read()\n",
    "    return robot.can_fetch(agent, urlparse(url)[2])\n",
    "    \n",
    "def download(url, params={}, headers={}, method='GET', limit=3):\n",
    "    method = method.upper()\n",
    "    if canfetch(url) == False:\n",
    "        print('[Error] ' + url)\n",
    "#     else: # 실제 수집할 때, 제약사항이 많으므로 여기선 잠시 해제\n",
    "    try:\n",
    "        resp = request(method, url,\n",
    "               params=params if method=='GET' else {},\n",
    "               data=params if method=='POST' else {},\n",
    "               headers=headers)\n",
    "        resp.raise_for_status()\n",
    "    except HTTPError as e:\n",
    "        if limit > 0 and e.response.status_code >= 500:\n",
    "            print(limit)\n",
    "            time.sleep(1) # => random\n",
    "            resp = download(url, params, headers, method, limit-1)\n",
    "        else:\n",
    "            print('[{}] '.format(e.response.status_code) + url)\n",
    "            print(e.response.status_code)\n",
    "            print(e.response.reason)\n",
    "            print(e.response.headers)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.google.com/search'\n",
    "params = {\n",
    "    'q':'',\n",
    "    'oq':'',\n",
    "    'aqs':'chrome..69i57j69i59j69i65l3j69i61j69i60j69i61.1205j0j7',\n",
    "    'sourceid':'chrome',\n",
    "    'ie':'UTF-8'\n",
    "}\n",
    "params['q'] = params['oq'] = '파이썬'\n",
    "headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "}\n",
    "resp = download(url, params, headers, 'GET')\n",
    "# dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "# # for _ in dom.find_all('h3', {'class':'LC20lb'}):\n",
    "# #     print(_.text.strip(), _.find_parents('a')[0]['href'])\n",
    "# for _ in dom.select('div.r > a'):\n",
    "#     print(_['href'], _.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://search.naver.com/search.naver'\n",
    "params = {\n",
    "    'sm':'top_hty',\n",
    "    'fbm':0,\n",
    "    'ie':'utf8',\n",
    "    'query':''\n",
    "}\n",
    "params['query'] = '파이썬'\n",
    "resp = download(url, params, headers, 'GET')\n",
    "dom = BeautifulSoup(resp.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in dom.find_all('ul', {'class':'type01'}):\n",
    "    for a in [dt.find('a') for dt in _.find_all('dt')]:\n",
    "        print(a['href'], a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in dom.select('.type01 dt > a'):\n",
    "    print(_['href'], _.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://search.daum.net/search'\n",
    "params = {\n",
    "    'w':'tot',\n",
    "    'DA':'YZR',\n",
    "    't__nil_searchbox':'btn',\n",
    "    'sug':'',\n",
    "    'sugo':'',\n",
    "    'sq':'',\n",
    "    'o':'',\n",
    "    'q':''\n",
    "}\n",
    "params['q'] = '파 이 썬'\n",
    "resp = download(url, params, headers, 'GET')\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dom.find_all('ul', {'class':'list_info mg_cont clear'})\n",
    "for _ in dom.find_all('div', {'class':'wrap_tit'}):\n",
    "    print(_.find('a')['href'], _.find('a').text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = download('http://pythonscraping.com/pages/page3.html')\n",
    "dom = BeautifulSoup(resp.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag, #id, .class, .class.class.class\n",
    "\n",
    "ul.class, ul.class.class.class\n",
    "tag, tag, tag => CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.select_one('div#footer') == dom.select_one('#footer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.select_one('#footer').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selector\n",
    "tag1, tag2\n",
    "tag1 tag2 => 자손 (find_all(recursive=True))\n",
    "tag1 > tag2 => 자식 (file_all(recursive=False))\n",
    "tag1 + tag2 => 형제(다음 노드) => tag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.select_one('#footer').find_parent().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dom.select('#wrapper > div')), len(dom.select('#wrapper > *'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_.name for _ in dom.select('#wrapper > *')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.select_one('h1 + div').name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.select_one('h1 + div').find_previous_sibling().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.select_one('body > div > h1 + div').name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_.text.strip() for _ in dom.select('.gift > td:nth-of-type(3)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_['src'].strip() for _ in dom.select('.gift > td > img')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://example.webscraping.com/places/default/index'\n",
    "resp = download(url)\n",
    "dom = BeautifulSoup(resp.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls.pop() 꺼낼, urls.append() 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Queue => FIFO => pop(0)\n",
    "Stack => LIFO => pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = list()\n",
    "seen = list()\n",
    "urls.append(url)\n",
    "\n",
    "while urls: # Queue\n",
    "    seed = urls.pop(0) # starting url\n",
    "    seen.append(seed) # => 재방문 회피\n",
    "    dom = BeautifulSoup(download(seed).text, 'html.parser') # HTTP\n",
    "#     for _ in dom.select('a'): # extract hyperlinks\n",
    "#         if _.has_attr('href'): # 나중에\n",
    "#             if _['href'].startswith('/'): # filter1\n",
    "#                 newUrls = urljoin(seed, _['href']) # Normalization\n",
    "#                 # query부분 (GET방식에서 ? 이후에 나오는 파라미터 생략)\n",
    "#                 if newUrls not in seen and newUrls not in urls: # \n",
    "#                     urls.append(newUrls)\n",
    "# #                     print(newUrls)\n",
    "    for _ in [_['href'] for _ in dom.select('a')\n",
    "              if _.has_attr('href') and _['href'].startswith('/')]:\n",
    "        newUrls = urljoin(seed, urlparse(_)[2])\n",
    "        if newUrls not in seen and newUrls not in urls:\n",
    "            urls.append(newUrls)\n",
    "    print(len(urls), len(seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http => ht{2}p\n",
    "https => https? => http, https\n",
    "helllllllllo => hel{1,}o\n",
    "다.                  그래서 => _+ => _\n",
    "다. 그래서\n",
    "[http]{3,4} => [h]tttp, [t]ttp, [p]pp => h | t | p\n",
    "ttph, http, htp\n",
    "h[t ]{1,}p\n",
    "65:[A-Z] => [ABCDEFGHIZKLMNoPQR... Z] 대소문자 구별\n",
    "97:[a-z] => [...]\n",
    "[ㄱ-ㅎ] => 자음\n",
    "[ㅏ-ㅣ] => 모음\n",
    "[가-힣] => 음절\n",
    "([가-힣]+)\n",
    "^x => SQL(x%)\n",
    "x$ => SQL(%x)\n",
    "[^x] => not x\n",
    "\\b => 공백 + 문자 + 공백\n",
    "\\B => 문자 + ? + 문자\n",
    "\\b[A-Za-z]+\\b => File Edit View Insert\n",
    "\\B[A-Za-z]+\\B => F(il)e E(di)t V(ie)w I(nser)t\n",
    "a href=\"javascript:~();#\" => \\W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '''\n",
    "park 800905-1049118\n",
    "kim  700905-1059119\n",
    "'''\n",
    "pattern = re.compile('(\\d{6})[-]\\d{7}')\n",
    "pattern.search(data)\n",
    "print(pattern.sub('\\g<1>-*******', data))\n",
    "# data[6:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(r'Crow|Servo', 'HelloServoCrowHello')\n",
    "re.search(r'^Crow|^Servo', 'HelloServoCrowHello')\n",
    "re.search(r'Hello$', 'HelloServoCrowHello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'(ABC)+', 'ABCABCA A').group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'\\bclass\\b', 'no class at all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'\\Bclass\\b', 'one subclass is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'\\Bclass\\B', 'the declassified algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.search(r'(\\w+) (\\w+)', 'Issac Newton, physicist')\n",
    "result.groups(), \\\n",
    "result.group(0), result.group(1), result.group(2)\n",
    "# $@#%단어 단어\n",
    "# \\b(\\w+)\\b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r'(\\w+) (\\w+)', r'\\g<2> \\g<1>', 'Issac Newton, physicist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "010-0000-0000 => 핸드폰번호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '010-0001-0002'\n",
    "data = '010 0000 0000'\n",
    "data = '010.0000.0000'\n",
    "data = '01000010002'\n",
    "data = '0232901338'\n",
    "result = re.search(r'(\\d{1,3})[- .]?(\\d{1,4})[- .]?(\\d{1,4})', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.group(0), result.group(1), result.group(2), result.group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'\\d+[-]\\d+[-]\\d+', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = '+82 2-0001-0002'\n",
    "# data = '+82 10-0001-0002'\n",
    "data = '+82 010-0001-0002'\n",
    "# data = '82 010-0001-0002'\n",
    "# ==> ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'[+]?\\d+.?\\d+.?\\d+.?\\d+', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = download('http://pythonscraping.com/pages/page3.html')\n",
    "# dom = BeautifulSoup(resp.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.search(r'([$]\\d+[.]\\d+)', resp.text).groups()\n",
    "re.findall(r'[$]\\d+[.]\\d+', resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'[$]\\d+[.]\\d+', resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'../img/gifts/img1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in re.findall(r'src=\"(.+?img\\d[.]jpg)\"', resp.text):\n",
    "    print(urljoin(resp.request.url, _))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'<span class=\"excitingNote\">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'<(span) class=\"[^\"]+\">(.+)</\\1>', resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_.strip() for _ in dom.find_all(text=re.compile(r'[.]\\d+$'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "이메일\n",
    "아이디@도메인\n",
    "회사명.com|net|org|kr\n",
    "    .co.kr|or.kr|go.kr|ac.kr\n",
    "\n",
    "아이디 규칙:영어로시작, 특수문자X, -, _, 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '''\n",
    "    test1@test.com\n",
    "    test2@test.co.kr\n",
    "    test3@email.test.com\n",
    "    test4@email.test.co.kr\n",
    "    12test@test.com\n",
    "    한글@test.com\n",
    "    test@test\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\b[A-Za-z][A-Za-z0-9-_.]+@[A-Za-z0-9-_]+(?:[.][A-Za-z0-9-_]+)+',\n",
    "           data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\b\\w+@', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://도메인 => O\n",
    "https://도메인 => O\n",
    "    \n",
    "ftp://도메인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '''\n",
    "    http://domain.com\n",
    "    http://www.domain.com\n",
    "    http://www.domain.co.kr\n",
    "    https://www.domain.com\n",
    "    https://www.domain.co.kr\n",
    "    https://www.domain.co.kr/\n",
    "    https://domain.co.kr/service\n",
    "    https://www.domain.co.kr/service\n",
    "    https://www.domain.co.kr/service/\n",
    "    https://domain.co.kr/service?key=value\n",
    "    https://www.domain.co.kr/service?key=value\n",
    "    https://www.domain.co.kr/service?key=value/\n",
    "    https://www.domain.co.kr/service/1/2?key=value\n",
    "    https://www.domain.co.kr/service/1/2?key=value/\n",
    "    ?key=value\n",
    "    www.domain.com?key=value\n",
    "    http://old.mail.domain.com?key=value\n",
    "    http://domain.com#key=value\n",
    "    http://www.domain.com?key=value\n",
    "    http://www.domain.com#key=value\n",
    "'''\n",
    "# Query String (?이후부분) 빼고, URI(L)을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'https?://\\w+(?:[./]\\w+)+', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\b파이썬\\B(\\w+)\\b', resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\b(\\w+)\\B파이썬\\b', resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\b파이썬\\b\n",
    "\\b(\\w+)\\B파이썬\\b\n",
    "\\b파이썬\\B(\\w+)\\b\n",
    "\n",
    "파이썬 파이썬 파이썬 = 3\n",
    "\n",
    "~파이썬 파이썬~\n",
    "은, 는, 이, 가~ => 명사\n",
    "강이지를, 강이지가, 강아지는 => Unique\n",
    "강아지+?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "()(강아지)(를) => \n",
    "()(강아지)(가) =>\n",
    "()(강아지)(는) =>\n",
    "(강아지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.google.com/search'\n",
    "params = {\n",
    "    'q':'',\n",
    "    'oq':'',\n",
    "    'aqs':'chrome..69i57j69i59j69i65l3j69i61j69i60j69i61.1205j0j7',\n",
    "    'sourceid':'chrome',\n",
    "    'ie':'UTF-8'\n",
    "}\n",
    "params['q'] = params['oq'] = '파이썬'\n",
    "headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "}\n",
    "resp = download(url, params, headers, 'GET')\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "urls = [{'url':_['href'], 'depth':1}\n",
    "        for _ in dom.select('div.r > a[href]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = list()\n",
    "\n",
    "while urls: # Queue\n",
    "    seed = urls.pop(-1)\n",
    "    seen.append(seed)\n",
    "    if seed['depth'] < 4: # 범위 제한 => Focused Crawling\n",
    "        dom = BeautifulSoup(download(seed['url']).text, 'html.parser')\n",
    "        for _ in [_['href'] for _ in dom.select('a[href]')\n",
    "                  if re.match(r'(?:https?:/)?/\\w+(?:[./]\\w+)+',\n",
    "                              _['href'])]:\n",
    "            newUrls = urljoin(seed['url'], urlparse(_)[2])\n",
    "            if newUrls not in [_['url'] for _ in seen] \\\n",
    "            and newUrls not in [_['url'] for _ in urls]:\n",
    "                urls.append({'url':newUrls, 'depth':seed['depth']+1})\n",
    "        print(len(urls), len(seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                  구글(검색어)-Queue(0)\n",
    "    [1]     [2]    3    4     5    6    7     8 -> done\n",
    "[1-1] 1-2 1-3 ..., 2-1, 2-2, ...\n",
    "1-1-1 1-1-2 ... => leaf\n",
    "=> BFS\n",
    "                  구글(검색어)-Stack(-1)\n",
    "    1     2    3    4     5    6    7     [8]\n",
    "                                      8-1 8-2 [8-3] ...,\n",
    "                                    8-3-1 [8-3-2] ... => leaf, done\n",
    "=> DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "구글(파이썬) -> 8개 검색결과(depth=1) -> 다시 링크타고 이동(depth=2) -> depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = '/www.domain.co.kr/service/1/2?key=value/'\n",
    "re.match(r'(?:https?:/)?/\\w+(?:[./]\\w+)+', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://search.naver.com/search.naver'\n",
    "params = {\n",
    "    'sm':'top_hty',\n",
    "    'fbm':0,\n",
    "    'ie':'utf8',\n",
    "    'query':''\n",
    "}\n",
    "params['query'] = '파이썬'\n",
    "resp = download(url, params, headers, 'GET')\n",
    "dom = BeautifulSoup(resp.content, 'html.parser')\n",
    "urls = [{'url':_['href'], 'depth':1}\n",
    "        for _ in dom.select('div.blog.section._blogBase._prs_blg dt > a[href]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = list()\n",
    "\n",
    "while urls: # Queue\n",
    "    seed = urls.pop(0)\n",
    "    seen.append(seed)\n",
    "    if seed['depth'] < 3: # 범위 제한 => Focused Crawling (수정)\n",
    "        dom = BeautifulSoup(download(seed['url']).text, 'html.parser')\n",
    "\n",
    "        for _ in [_['href'] if _.has_attr('href') else _['src'] # 여기\n",
    "                  for _ in dom.select('a[href], #mainFrame')\n",
    "                  if re.match(r'(?:https?:/)?/\\w+(?:[./]\\w+)+',\n",
    "                _['href'] if _.has_attr('href') else _['src'])]: # 여기\n",
    "            newUrls = urljoin(seed['url'], _) # 여기\n",
    "            if urlparse(newUrls)[1] in ['blog.naver.com'] \\\n",
    "            and newUrls not in [_['url'] for _ in seen] \\\n",
    "            and newUrls not in [_['url'] for _ in urls]:# (수정)도메인 제한\n",
    "                urls.append({'url':newUrls, 'depth':seed['depth']+1})\n",
    "        print(len(urls), len(seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('pagerank.db')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.executescript('''\n",
    "    DROP TABLE IF EXISTS host;\n",
    "    CREATE TABLE host(\n",
    "        pk      INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "        netloc  TEXT NOT NULL\n",
    "    );\n",
    "    DROP TABLE IF EXISTS url;\n",
    "    CREATE TABLE url(\n",
    "        pk      INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "        fk      INTEGER NOT NULL,\n",
    "        ref     INTEGER NOT NULL,\n",
    "        path    TEXT NOT NULL,\n",
    "        crawled TEXT NOT NULL\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.google.com/search'\n",
    "params = {\n",
    "    'q':'',\n",
    "    'oq':'',\n",
    "    'aqs':'chrome..69i57j69i59j69i65l3j69i61j69i60j69i61.1205j0j7',\n",
    "    'sourceid':'chrome',\n",
    "    'ie':'UTF-8'\n",
    "}\n",
    "params['q'] = params['oq'] = '파이썬'\n",
    "headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "}\n",
    "resp = download(url, params, headers, 'GET')\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "for _ in dom.select('div.r > a[href]'):\n",
    "    urlseg = urlparse(_['href'])\n",
    "    # url => http://netloc/path?query\n",
    "    # netloc = htttp://netloc\n",
    "    netloc = '://'.join(urlseg[:2])\n",
    "    # path = path?query\n",
    "    path = urlseg[2]+('?'+urlseg[4] if urlseg[4] else '')\n",
    "    # host테이블에 netloc이 있는지 확인\n",
    "    cur.execute('SELECT pk FROM host WHERE netloc=? ORDER BY pk ASC LIMIT 0,1',\n",
    "            ['://'.join(urlseg[:2]),])\n",
    "    # 없다면,\n",
    "    if not cur.fetchone():\n",
    "        # host테이블에 netloc 추가\n",
    "        cur.execute('INSERT INTO host(netloc) VALUES(?)',\n",
    "                    ['://'.join(urlseg[:2]),])\n",
    "        con.commit()\n",
    "    # url테이블에 path 추가 (단, host테이블 netloc의 pk를 fk로 가져옴)\n",
    "    cur.execute('''\n",
    "    INSERT INTO url(fk, ref, path, crawled)\n",
    "    VALUES((SELECT pk FROM host WHERE netloc=? ORDER BY pk LIMIT 0, 1), ?, ?, 'N')\n",
    "    ''', [netloc, 0, path])\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while range(1000):#True:\n",
    "for _ in range(100):\n",
    "    cur.execute('''\n",
    "        SELECT host.pk, url.pk, host.netloc, url.path FROM url\n",
    "        INNER JOIN host ON host.pk=url.fk\n",
    "        WHERE url.crawled='N'\n",
    "        ORDER BY url.pk ASC\n",
    "        LIMIT 0,1\n",
    "    ''')\n",
    "    seed = cur.fetchone()\n",
    "\n",
    "    if not seed:\n",
    "        break\n",
    "        \n",
    "    cur.execute('''\n",
    "        UPDATE url SET crawled='Y' WHERE pk=?\n",
    "    ''', [seed[1],])\n",
    "    url = ''.join(seed[2:])\n",
    "    dom = BeautifulSoup(download(url).text, 'html.parser')\n",
    "    for _ in [_['href'] for _ in dom.select('a[href]')\n",
    "              if re.match(r'(?:https?:/)?/\\w+(?:[./]\\w+)+',\n",
    "                          _['href'])]:\n",
    "        urlseg = urlparse(urljoin(url, _))\n",
    "        netloc = '://'.join(urlseg[:2])\n",
    "        path = urlseg[2]+('?'+urlseg[4] if urlseg[4] else '')\n",
    "        cur.execute('''\n",
    "            SELECT pk FROM host WHERE netloc=?\n",
    "            ORDER BY pk ASC LIMIT 0,1''', ['://'.join(urlseg[:2]),])\n",
    "        if not cur.fetchone():\n",
    "            cur.execute('INSERT INTO host(netloc) VALUES(?)',\n",
    "                        ['://'.join(urlseg[:2]),])\n",
    "            con.commit()\n",
    "            \n",
    "        cur.execute('''\n",
    "            SELECT count(pk) FROM url WHERE fk=? and path=?\n",
    "        ''', [seed[0], path])\n",
    "        \n",
    "        if cur.fetchone()[0] < 1:\n",
    "            cur.execute('''\n",
    "            INSERT INTO url(fk, ref, path, crawled)\n",
    "            VALUES((SELECT pk FROM host WHERE netloc=? ORDER BY pk LIMIT 0, 1), ?, ?, 'N')\n",
    "            ''', [netloc, seed[0], path])\n",
    "            con.commit()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('SELECT COUNT(pk) FROM host')\n",
    "cnt = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((cnt+1,cnt+1))\n",
    "v = np.zeros((cnt+1,))\n",
    "S = np.zeros((cnt+1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1,cnt+1):\n",
    "    cur.execute('''\n",
    "        SELECT fk, count(fk) FROM url\n",
    "        WHERE ref=? GROUP BY fk''', [j,])\n",
    "    \n",
    "    for i in cur:\n",
    "        A[i[0],j] = i[1]\n",
    "        S[j] += i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = A/S\n",
    "AA[np.isnan(AA)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[:] = 1/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    v = AA.dot(v)\n",
    "    print('Iter:{}'.format(_+1))\n",
    "    for _ in v.argsort()[::-1][:5]:\n",
    "        cur.execute('SELECT * FROM host WHERE pk=?', [str(_),])\n",
    "        print(cur.fetchone(), np.round(v[_], 10),\n",
    "              A[:,_].sum(), A[_].sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0])/np.array([0]), \\\n",
    "np.array([0])/np.array([1]), \\\n",
    "np.array([1])/np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.ppomppu.co.kr/zboard/zboard.php'\n",
    "\n",
    "params = {\n",
    "    'id':'ppomppu',\n",
    "    'page':1\n",
    "}\n",
    "headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawling[링크] + Scraping[내용]\n",
    "# Focused Crawling - 게시판의 파라미터로 제한\n",
    "for page in range(1,10):\n",
    "    params['page'] = page\n",
    "    resp = download(url, params, headers, 'GET')\n",
    "    dom = BeautifulSoup(resp.text, 'lxml')\n",
    "    \n",
    "    # Scraping\n",
    "    for _ in dom.select('#revolution_main_table tr[class^=list]')[1:]:\n",
    "        item = dict()\n",
    "        td = _.find_all('td', recursive=False)\n",
    "        temp = title.findall(td[3].text)\n",
    "        frag1 = temp[0] if len(temp) > 0 else td[3].text.strip()\n",
    "        frag2 = td[-2].text.split('-')\n",
    "\n",
    "        item['mall'] = frag1[0].strip()\n",
    "        item['title'] = frag1[1].strip()\n",
    "        item['price'] = frag1[2].strip()\n",
    "        item['tu'] = frag2[0].strip() if len(frag2) > 1 else 0\n",
    "        item['td'] = frag2[1].strip() if len(frag2) > 1 else 0\n",
    "        print(item)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.ppomppu.co.kr/zboard/zboard.php?id=ppomppu'\n",
    "headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "}\n",
    "\n",
    "urls = list()\n",
    "seen = list()\n",
    "\n",
    "urls.append(url)\n",
    "\n",
    "while urls:\n",
    "    seed = urls.pop(0)\n",
    "    seen.append(seed)\n",
    "\n",
    "    dom = BeautifulSoup(download(seed).text, 'lxml')\n",
    "    for _ in [_['href']\n",
    "              for _ in dom.select('''\n",
    "              tr.list0 a[href], tr.list1 a[href], #page_list a[href]\n",
    "              ''')\n",
    "              if re.match(r'(?:https?:/)?/\\w+(?:[./]\\w+)+', _['href'])]:\n",
    "        newUrls = urljoin(seed, _)\n",
    "        if newUrls not in urls \\\n",
    "        and newUrls not in seen:\n",
    "            urls.append(newUrls)\n",
    "    print(len(urls), len(seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping\n",
    "for _ in dom.select('#revolution_main_table tr[class^=list]')[1:]:\n",
    "    item = dict()\n",
    "    td = _.find_all('td')\n",
    "    frag1 = title.findall(td[3].text)[0]\n",
    "    frag2 = td[-2].text.split('-')\n",
    "    \n",
    "    item['mall'] = frag1[0].strip()\n",
    "    item['title'] = frag1[1].strip()\n",
    "    item['price'] = frag1[2].strip()\n",
    "    item['tu'] = frag2[0].strip() if len(frag2) > 1 else 0\n",
    "    item['td'] = frag2[1].strip() if len(frag2) > 1 else 0\n",
    "    print(item)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = re.compile(r'[[]?(\\w+)[]]?([^(]+)[(](.+?)[)]')\n",
    "price = re.compile(r'(.+?)[ /](.+?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[]? => (문자)[ 있고, 없고  \\[\n",
    " (\\w+) => 글자 1개 이상 (1)\n",
    " []]? => (문자)] 있고, 없고\n",
    "\n",
    "([^(]+) => (그룹) (문자)(가 아닌 다른 문자가 1개 이상 (2)\n",
    "  [(] => (문자)( 있고\n",
    "    (.+?) => 아무글자나 1개 이상(Lazy)  (3)\n",
    "    [)] => (문자)) 있고\n",
    "    \n",
    "[(1=???)] (2=???????) ((3=????))\n",
    "[LG] 통돌이 모델명 (가격)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.ppomppu.co.kr/zboard/zboard.php?id=freeboard&page=1'\n",
    "\n",
    "params = {\n",
    "    'id':'freeboard',\n",
    "    'page':1\n",
    "}\n",
    "headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = list()\n",
    "seen = list()\n",
    "\n",
    "urls.append({'url':url, 'depth':1})\n",
    "\n",
    "while urls:\n",
    "    seed = urls.pop(0)\n",
    "    seen.append(seed)\n",
    "    \n",
    "    if seed['depth'] > 3:\n",
    "        break\n",
    "        \n",
    "    resp = download(seed['url'])\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "    # 한 줄로\n",
    "    for _ in dom.select('.list0 > td:nth-of-type(3) a, .list1 > td:nth-of-type(3) a, #page_list a'):\n",
    "        if _['href'][0] in ['v', '/']:\n",
    "            newurl = urljoin(url, _['href'])\n",
    "            if newurl not in [_['url'] for _ in urls] and\\\n",
    "               newurl not in [_['url'] for _ in seen]:\n",
    "                urls.append({'url':newurl,\n",
    "                             'depth':seed['depth']+1})\n",
    "    # 여기까지가 크롤링\n",
    "            \n",
    "    # 여기서부터가 스크래핑\n",
    "    if dom.select_one('.board-contents') != None:\n",
    "        print(\n",
    "            {'head':dom.select_one('.view_title2').text.strip(),\n",
    "             'body':dom.select_one('.board-contents').text.strip(),\n",
    "             'comments':[_.text.strip()\n",
    "                         for _ in dom.select('.comment_wrapper .han')]})\n",
    "        print()\n",
    "    if seed['depth'] > 1 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = download(seed['url'])\n",
    "dom = BeautifulSoup(resp.text, 'lxml')\n",
    "dom.select('.board-contents')\n",
    "dom.select('table.pic_bg table table > tr > td:nth-of-type(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://example.webscraping.com/places/default/search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = download(url)\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajax = '/places/ajax/search.json'\n",
    "params = {\n",
    "    'search_term':'united',\n",
    "    'page_size':10,\n",
    "    'page':0\n",
    "}\n",
    "resp = download(urljoin(url, ajax), params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.status_code, resp.reason, resp.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in result['records']:\n",
    "    print(_['id'])\n",
    "    print(_['country'])\n",
    "    print(_['pretty_link'])\n",
    "    print()\n",
    "    print(urljoin(url, re.search(r'href=\"([^\"]+)\"', _['pretty_link']).group(1)))\n",
    "    print(urljoin(url, re.search(r'src=\"([^\"]+)\"', _['pretty_link']).group(1)))\n",
    "    print(re.search(r'>\\s*([^<]+)<', _['pretty_link']).group(1))\n",
    "    print()\n",
    "    dom = BeautifulSoup(_['pretty_link'], 'html.parser')\n",
    "    print(urljoin(url, dom.a['href']))\n",
    "    print(urljoin(url, dom.img['src']))\n",
    "    print(dom.a.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.find('div', {'id':'results'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "주소: dom.select_one('form')\n",
    "파라미터: <form action=주소>?search_term=국가명&page_size=10&page=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://pythonscraping.com/pages/cookies/login.html'\n",
    "resp = download(url)\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "dom.form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "for _ in dom.select('input[name]'):\n",
    "    params[_['name']] = 'anything' if _['name'] == 'username' else 'password'\n",
    "\n",
    "resp = download(urljoin(url, dom.form['action']), params=params, method='POST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.request.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request(쿠키X) == session(쿠키O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = session.request('POST', urljoin(url, dom.form['action']), data=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.cookies.get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = session.request('GET', urljoin(url, dom.form['action']))\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = request('GET', urljoin(url, dom.form['action']))\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = request('GET', urljoin(url, dom.form['action']), cookies=session.cookies)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookiedict = {}\n",
    "for _ in session.cookies.items():\n",
    "    cookiedict[_[0]] = _[1]\n",
    "cookiedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = request('GET', urljoin(url, dom.form['action']), cookies=cookiedict)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = download('https://nid.naver.com/nidlogin.login?mode=form', headers=headers)\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "for _ in dom.form.select('input[name]'):\n",
    "    params[_['name']] = _['value'] if _.has_attr('value') else ''\n",
    "params['id'] = 'test'\n",
    "params['pw'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params, dom.form['action'], dom.form['method']\n",
    "resp = session.request(dom.form['method'], dom.form['action'], data=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookiedict = {\n",
    "    'nid_enctp':'1',\n",
    "    'nid_slevel':'-1',\n",
    "    'nid_buk':'WXRK2GDR3ZHV2',\n",
    "    'NID_SES':'AAABrrgO8DjwAvFazDJR4cPaqRTLp7V9vUaODcCbAQQPArasE8sFemWX4wt8mXbiOrJhD4MXj0aGGjugFVN4PbNYPgyhrDsq87LVo32NpXSuSIzCgZdvelF2X6LgUaCNyGKtNPhPeYo96jFEme088chW1bWQv4hJQTtTojvprFlptVVTvjF2m9bx70EPmxsEkJuWDe/yeHknaYObVM7VnTOTqBJX5bmyXVEnHISSXhJibbq9J0/7VbihZl/Ovj5/wNP+5h1JJ5/p6I3PKQ7rXTr7tf+W6YHOr89KvC11I9IRXw9ZVF5krQevHc1nazuN/lpvMY12XS9zEmgIi6whdqJwkRWDDloAHFS+k2OShJBb2mF2NTtgLIfXIN8Uy4Rv4+eIvIFoQSYxg+pn3d9oCOXFfcQjD9N9NOnJNuf/xJzl57dfhEZeGWS0XLO23wq7qKX798FD89gCF+aMLz5RRzWk4PSZ/QCtsVFuDCcC55fNWRAd2HLnv8hP4qMILj+GyPrYDxtcCO3q4DD8wJevdNEn5mYp8sKadzUxnT3GlOVfXjanbhRMyi1fTAIQrLDp23a1uw==',\n",
    "    'NID_AUT':'oY2OPRXPzNGU+ghXwLtIcuaRXJBwvSvxyGFqeSx2o+rB3JO57imKwrUSmsLXnL5f',\n",
    "    'BMR':'s=1595301162847&r=https%3A%2F%2Fm.blog.naver.com%2FPostView.nhn%3FblogId%3Dwideeyed%26logNo%3D221581064062%26proxyReferer%3Dhttps%3A%252F%252Fwww.google.com%252F&r2=https%3A%2F%2Fwww.google.com%2F',\n",
    "    'NMUSER':'u9nlKqEwaqbsFxb9aAEXpre5KAuZKxnwFxv9Kq2dKqU/aqEwKogsKAnsadEsFAtqKxMZaw/wFxRpad/syqvs6xRpa9vs6xnstonsarRTBdRLa9vstonsH405pzk/7xE5W4d5W4JrpBU5MreR7A2lKAgsbrkoWrlvMBil7605pzk/7xE5W4d5W4JrpBU5MreR7A2lKAgs',\n",
    "    'nid_inf':'-1526038770',\n",
    "    'page_uid':'UxS6lwp0J14ssBvo6v4ssssssl8-024504',\n",
    "    'NRTK':'ag#30s_gr#1_ma#-2_si#0_en#0_sp#0',\n",
    "    'nx_ssl':'2',\n",
    "    'ASID':'79a0031c0000016f12de67ad0000073c',\n",
    "    'NNB':'WXRK2GDR3ZHV2',\n",
    "    'NID_JKL':'dM16byvI0qNjDzd4HylqTQlhNpuUL55zR0XD7flimUc='\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mail.naver.com/'\n",
    "session.cookies.clear()\n",
    "for k, v in cookiedict.items():\n",
    "    session.cookies.set(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = session.request('GET', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.find(text='전체메일').find_parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.select_one('#list_for_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailapi = 'https://mail.naver.com/json/list/'\n",
    "params = {\n",
    "    'page':'1',\n",
    "    'sortField':'1',\n",
    "    'sortType':'0',\n",
    "    'folderSN':'5',\n",
    "    'type':'',\n",
    "    'isUnread':'false',\n",
    "    'u':'gon0121'\n",
    "}\n",
    "resp = session.request('POST', mailapi, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in resp.json()['mailData']:\n",
    "    print(_['from'])\n",
    "    print(_['subject'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://lms.sunde41.net/auth/login'\n",
    "resp = download(url)\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.form['action'], dom.form['method']\n",
    "params = {}\n",
    "for _ in dom.form.select('input[name]'):\n",
    "    params[_['name']] = _['value'] if _.has_attr('value') else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lms.json\n",
    "{\n",
    "    \"id\":\"gon0121@gmail.com\",\n",
    "    \"pw\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('lms.json') as f:\n",
    "    account = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['email'] = account['id']\n",
    "params['password'] = account['pw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.cookies.clear()\n",
    "resp = session.post(urljoin(url, dom.form['action']), data=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://lms.sunde41.net/course/2'\n",
    "resp = session.get(url)\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notice = dom.select_one('\n",
    "'#notice-table tr:nth-of-type(2) td:nth-of-type(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'href=\"([^\"]+)\"', notice.decode()).group(1)\n",
    "re.search(r'href=\"([^\"]+)\"', notice.decode()).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\s+(\\d+)<', notice.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r'(T.+)', '',\n",
    "       notice.find_previous_sibling().span.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://lms.sunde41.net/auth/login'\n",
    "resp = download(url)\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "dom.form['action'], dom.form['method']\n",
    "params = {}\n",
    "for _ in dom.form.select('input[name]'):\n",
    "    params[_['name']] = _['value'] if _.has_attr('value') else ''\n",
    "    \n",
    "with open('lms.json') as f:\n",
    "    account = json.load(f)\n",
    "    \n",
    "params['email'] = account['id']\n",
    "params['password'] = account['pw']\n",
    "\n",
    "session.cookies.clear()\n",
    "resp = session.post(urljoin(url, dom.form['action']), data=params)\n",
    "\n",
    "url = 'https://lms.sunde41.net/course/2'\n",
    "resp = session.get(url)\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "notice = dom.select_one('#notice-table tr:nth-of-type(2) td:nth-of-type(2)')\n",
    "\n",
    "date = re.sub(r'(T.+)', '',\n",
    "       notice.find_previous_sibling().span.text.strip())\n",
    "addr = re.search(r'href=\"([^\"]+)\"', notice.decode()).group(1)\n",
    "user = re.findall(r'\\s+(\\d+)<', notice.decode())\n",
    "print('날짜: {}'.format(date))\n",
    "print('주소: {}'.format(addr))\n",
    "print('아이디: {0} / 비밀번호: {1}'.format(user[0], user[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pubmed.ncbi.nlm.nih.gov/'\n",
    "resp = download(url)\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom.form['action'], dom.form['method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "for _ in dom.form.select('input[name]'):\n",
    "    params[_['name']] = _['value'] if _.has_attr('value') else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['term'] = 'COVID-19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = download(urljoin(url, dom.form['action']),\n",
    "                params=params, method=dom.form['method'].upper())\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in dom.select('a.docsum-title'):\n",
    "    print(urljoin(url, _['href']))\n",
    "    print(_.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pubmed.ncbi.nlm.nih.gov/more/'\n",
    "params = {\n",
    "    'term':'',\n",
    "    'no_cache':'yes',\n",
    "    'page':1,\n",
    "    'no-cache':'1595396715871',\n",
    "    'csrfmiddlewaretoken':'2wIXZqSa2DKMGL87wdSZyN0N8JspiyFROV04RsCLcFNmGqgKWa0729B5n2ohOoC6'\n",
    "}\n",
    "params['term'] = 'COVID-19'\n",
    "\n",
    "for page in range(1, 11):\n",
    "    params['page'] = page\n",
    "\n",
    "    resp = download(url, params, headers, 'POST')\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "    for _ in dom.select('a.docsum-title'):\n",
    "        print(urljoin(url, _['href']))\n",
    "        print(_.text.strip())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.cookies.clear()\n",
    "resp = session.get('https://pubmed.ncbi.nlm.nih.gov/',\n",
    "                   params={'term':'COVID-19'})\n",
    "referer = resp.request.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header -> Referer, Token 둘다검사 -> Bot 체크\n",
    "session.cookies.clear()\n",
    "resp = session.get('https://pubmed.ncbi.nlm.nih.gov/',\n",
    "                   params={'term':'COVID-19'})\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "print('1페이지')\n",
    "for _ in dom.select('a.docsum-title'):\n",
    "    print(urljoin(url, _['href']))\n",
    "    print(_.text.strip())\n",
    "    print()\n",
    "print()\n",
    "referer = resp.request.url\n",
    "\n",
    "params = {\n",
    "    'term':'COVID-19',\n",
    "    'no_cache':'yes',\n",
    "    'page':1,\n",
    "    'no-cache':'1595396715871',\n",
    "    'csrfmiddlewaretoken':session.cookies.get('pm-csrf')\n",
    "}\n",
    "\n",
    "for page in range(2, 11):\n",
    "    params['page'] = page\n",
    "    \n",
    "    resp = session.post('https://pubmed.ncbi.nlm.nih.gov/more/',\n",
    "                        data=params, headers={'referer':referer})\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    print('{}페이지'.format(page))\n",
    "    for _ in dom.select('a.docsum-title'):\n",
    "        print(urljoin(url, _['href']))\n",
    "        print(_.text.strip())\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
